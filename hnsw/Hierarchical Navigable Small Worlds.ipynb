{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a95d4579-1473-4b7f-942a-223447dff53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building HNSW index with 10000 points...\n",
      "Inserted 100/10000 points\n",
      "Inserted 200/10000 points\n",
      "Inserted 300/10000 points\n",
      "Inserted 400/10000 points\n",
      "Inserted 500/10000 points\n",
      "Inserted 600/10000 points\n",
      "Inserted 700/10000 points\n",
      "Inserted 800/10000 points\n",
      "Inserted 900/10000 points\n",
      "Inserted 1000/10000 points\n",
      "Inserted 1100/10000 points\n",
      "Inserted 1200/10000 points\n",
      "Inserted 1300/10000 points\n",
      "Inserted 1400/10000 points\n",
      "Inserted 1500/10000 points\n",
      "Inserted 1600/10000 points\n",
      "Inserted 1700/10000 points\n",
      "Inserted 1800/10000 points\n",
      "Inserted 1900/10000 points\n",
      "Inserted 2000/10000 points\n",
      "Inserted 2100/10000 points\n",
      "Inserted 2200/10000 points\n",
      "Inserted 2300/10000 points\n",
      "Inserted 2400/10000 points\n",
      "Inserted 2500/10000 points\n",
      "Inserted 2600/10000 points\n",
      "Inserted 2700/10000 points\n",
      "Inserted 2800/10000 points\n",
      "Inserted 2900/10000 points\n",
      "Inserted 3000/10000 points\n",
      "Inserted 3100/10000 points\n",
      "Inserted 3200/10000 points\n",
      "Inserted 3300/10000 points\n",
      "Inserted 3400/10000 points\n",
      "Inserted 3500/10000 points\n",
      "Inserted 3600/10000 points\n",
      "Inserted 3700/10000 points\n",
      "Inserted 3800/10000 points\n",
      "Inserted 3900/10000 points\n",
      "Inserted 4000/10000 points\n",
      "Inserted 4100/10000 points\n",
      "Inserted 4200/10000 points\n",
      "Inserted 4300/10000 points\n",
      "Inserted 4400/10000 points\n",
      "Inserted 4500/10000 points\n",
      "Inserted 4600/10000 points\n",
      "Inserted 4700/10000 points\n",
      "Inserted 4800/10000 points\n",
      "Inserted 4900/10000 points\n",
      "Inserted 5000/10000 points\n",
      "Inserted 5100/10000 points\n",
      "Inserted 5200/10000 points\n",
      "Inserted 5300/10000 points\n",
      "Inserted 5400/10000 points\n",
      "Inserted 5500/10000 points\n",
      "Inserted 5600/10000 points\n",
      "Inserted 5700/10000 points\n",
      "Inserted 5800/10000 points\n",
      "Inserted 5900/10000 points\n",
      "Inserted 6000/10000 points\n",
      "Inserted 6100/10000 points\n",
      "Inserted 6200/10000 points\n",
      "Inserted 6300/10000 points\n",
      "Inserted 6400/10000 points\n",
      "Inserted 6500/10000 points\n",
      "Inserted 6600/10000 points\n",
      "Inserted 6700/10000 points\n",
      "Inserted 6800/10000 points\n",
      "Inserted 6900/10000 points\n",
      "Inserted 7000/10000 points\n",
      "Inserted 7100/10000 points\n",
      "Inserted 7200/10000 points\n",
      "Inserted 7300/10000 points\n",
      "Inserted 7400/10000 points\n",
      "Inserted 7500/10000 points\n",
      "Inserted 7600/10000 points\n",
      "Inserted 7700/10000 points\n",
      "Inserted 7800/10000 points\n",
      "Inserted 7900/10000 points\n",
      "Inserted 8000/10000 points\n",
      "Inserted 8100/10000 points\n",
      "Inserted 8200/10000 points\n",
      "Inserted 8300/10000 points\n",
      "Inserted 8400/10000 points\n",
      "Inserted 8500/10000 points\n",
      "Inserted 8600/10000 points\n",
      "Inserted 8700/10000 points\n",
      "Inserted 8800/10000 points\n",
      "Inserted 8900/10000 points\n",
      "Inserted 9000/10000 points\n",
      "Inserted 9100/10000 points\n",
      "Inserted 9200/10000 points\n",
      "Inserted 9300/10000 points\n",
      "Inserted 9400/10000 points\n",
      "Inserted 9500/10000 points\n",
      "Inserted 9600/10000 points\n",
      "Inserted 9700/10000 points\n",
      "Inserted 9800/10000 points\n",
      "Inserted 9900/10000 points\n",
      "Inserted 10000/10000 points\n",
      "HNSW index built with 10000 points\n",
      "Distance computations: 2357\n",
      "Entry point level: 3\n",
      "\n",
      "Top 10 results:\n",
      "  1. Point 2360: distance = 5.6470\n",
      "  2. Point 1218: distance = 5.7195\n",
      "  3. Point 1333: distance = 5.8222\n",
      "  4. Point 8079: distance = 5.8315\n",
      "  5. Point 2285: distance = 5.8434\n",
      "  6. Point 143: distance = 5.8515\n",
      "  7. Point 8482: distance = 5.8650\n",
      "  8. Point 2490: distance = 5.8731\n",
      "  9. Point 9263: distance = 5.8737\n",
      "  10. Point 3013: distance = 5.8750\n",
      "BRUTE FORCE SEARCH\n",
      "Distance computations: 10000\n",
      "\n",
      "Top 10 results:\n",
      "  1. Point 2360: distance = 5.6470\n",
      "  2. Point 9788: distance = 5.7190\n",
      "  3. Point 1218: distance = 5.7195\n",
      "  4. Point 5228: distance = 5.7996\n",
      "  5. Point 8188: distance = 5.8148\n",
      "  6. Point 1333: distance = 5.8222\n",
      "  7. Point 556: distance = 5.8297\n",
      "  8. Point 8079: distance = 5.8315\n",
      "  9. Point 2285: distance = 5.8434\n",
      "  10. Point 143: distance = 5.8515\n",
      "COMPARISON\n",
      "Distance computation reduction: 4.24x\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "\n",
    "number_of_samples = 10000\n",
    "N_max = 16\n",
    "d = 256\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_id):\n",
    "        self.node_id = node_id\n",
    "        self.neighbors = []\n",
    "    \n",
    "    def get_neighbors(self):\n",
    "        return self.neighbors\n",
    "    \n",
    "    def add_neighbor(self, neighbor_id):\n",
    "        if neighbor_id not in self.neighbors:\n",
    "            self.neighbors.append(neighbor_id)\n",
    "    \n",
    "    def remove_neighbor(self, neighbor_id):\n",
    "        if neighbor_id in self.neighbors:\n",
    "            self.neighbors.remove(neighbor_id)\n",
    "\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, start_id, end_id):\n",
    "        assert start_id != end_id, \"No self loops\"\n",
    "        self.start_id = start_id\n",
    "        self.end_id = end_id\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, nodes=None, edges=None):\n",
    "        self.nodes = {}\n",
    "        self.edges = edges if edges is not None else []\n",
    "        \n",
    "        if nodes:\n",
    "            for node in nodes:\n",
    "                self.nodes[node.node_id] = node\n",
    "\n",
    "    def add_node(self, node):\n",
    "        self.nodes[node.node_id] = node\n",
    "\n",
    "    def add_edge(self, edge):\n",
    "        self.edges.append(edge)\n",
    "        if edge.start_id in self.nodes:\n",
    "            self.nodes[edge.start_id].add_neighbor(edge.end_id)\n",
    "\n",
    "    def add_bi_directional_edge(self, start_id, end_id):\n",
    "        self.add_edge(Edge(start_id, end_id))\n",
    "        self.add_edge(Edge(end_id, start_id))\n",
    "\n",
    "    def get_node(self, node_id):\n",
    "        return self.nodes.get(node_id, None)\n",
    "\n",
    "\n",
    "class HNSW:\n",
    "    def __init__(self, sample_nr, n_max, ef_construction=200):\n",
    "        self.samples = np.random.random((sample_nr, d))\n",
    "        self.sample_nr = sample_nr\n",
    "        self.n_max = n_max\n",
    "        self.ef_construction = ef_construction\n",
    "        self.entry_point_id = None\n",
    "        self.initialize_graph()\n",
    "\n",
    "    def draw_levels(self):\n",
    "        seeds = np.random.uniform(low=0, high=1, size=self.sample_nr)\n",
    "        m_L = 1 / np.log(self.n_max)\n",
    "        return np.floor(-np.log(seeds) * m_L).astype(np.int32)\n",
    "\n",
    "    def setup_level_graphs(self):\n",
    "        self.level_graphs = [None] * (self.max_levels.max() + 1)\n",
    "        for level in range(self.max_levels.max() + 1):\n",
    "            self.level_graphs[level] = Graph([], [])\n",
    "        \n",
    "    def distance(self, id1, id2):\n",
    "        return np.linalg.norm(self.samples[id1] - self.samples[id2])\n",
    "    \n",
    "    def distance_vector(self, vector, id2):\n",
    "        return np.linalg.norm(vector - self.samples[id2])\n",
    "\n",
    "    def greedy_search(self, query_id, entry_point_id, stop_at):\n",
    "        entry_point_max_level = self.max_levels[entry_point_id]\n",
    "        assert stop_at <= entry_point_max_level, \"Entry point started below stop_at level\"\n",
    "\n",
    "        closest_match = entry_point_id\n",
    "        min_distance = self.distance(closest_match, query_id)\n",
    "        \n",
    "        for level in range(entry_point_max_level, stop_at - 1, -1):\n",
    "            change = True\n",
    "            while change:\n",
    "                node = self.level_graphs[level].get_node(closest_match)\n",
    "                if node is None:\n",
    "                    break\n",
    "                    \n",
    "                neighbors = node.get_neighbors()\n",
    "                if len(neighbors) == 0:\n",
    "                    change = False\n",
    "                    continue\n",
    "    \n",
    "                closest_neighbor_info = min(\n",
    "                    [(n_id, self.distance(query_id, n_id)) for n_id in neighbors], \n",
    "                    key=lambda pair: pair[1]\n",
    "                )\n",
    "\n",
    "                if closest_neighbor_info[1] < min_distance:\n",
    "                    closest_match = closest_neighbor_info[0]\n",
    "                    min_distance = closest_neighbor_info[1]\n",
    "                else:\n",
    "                    change = False\n",
    "\n",
    "        return closest_match\n",
    "    \n",
    "    def greedy_search_vector(self, query_vector, entry_point_id, stop_at, stats=None):\n",
    "        entry_point_max_level = self.max_levels[entry_point_id]\n",
    "        assert stop_at <= entry_point_max_level, \"Entry point started below stop_at level\"\n",
    "\n",
    "        closest_match = entry_point_id\n",
    "        min_distance = self.distance_vector(query_vector, closest_match)\n",
    "        \n",
    "        for level in range(entry_point_max_level, stop_at - 1, -1):\n",
    "            if stats is not None:\n",
    "                stats['levels_visited'].append(level)\n",
    "            \n",
    "            change = True\n",
    "            while change:\n",
    "                node = self.level_graphs[level].get_node(closest_match)\n",
    "                if node is None:\n",
    "                    break\n",
    "                    \n",
    "                neighbors = node.get_neighbors()\n",
    "                if len(neighbors) == 0:\n",
    "                    change = False\n",
    "                    continue\n",
    "                \n",
    "                if stats is not None:\n",
    "                    stats['distance_computations'] += len(neighbors)\n",
    "    \n",
    "                closest_neighbor_info = min(\n",
    "                    [(n_id, self.distance_vector(query_vector, n_id)) for n_id in neighbors], \n",
    "                    key=lambda pair: pair[1]\n",
    "                )\n",
    "\n",
    "                if closest_neighbor_info[1] < min_distance:\n",
    "                    closest_match = closest_neighbor_info[0]\n",
    "                    min_distance = closest_neighbor_info[1]\n",
    "                else:\n",
    "                    change = False\n",
    "\n",
    "        return closest_match\n",
    "\n",
    "    def beam_search(self, query_id, entry_point_ids, level):\n",
    "        candidates = PriorityQueue()\n",
    "        visited = set()\n",
    "        results = []\n",
    "        \n",
    "        for ep_id in entry_point_ids if isinstance(entry_point_ids, list) else [entry_point_ids]:\n",
    "            dist = self.distance(query_id, ep_id)\n",
    "            candidates.put((dist, ep_id))\n",
    "            visited.add(ep_id)\n",
    "            results.append((ep_id, dist))\n",
    "        \n",
    "        while not candidates.empty():\n",
    "            current_dist, current_id = candidates.get()\n",
    "            \n",
    "            if len(results) >= self.ef_construction:\n",
    "                furthest_dist = max(results, key=lambda x: x[1])[1]\n",
    "                if current_dist > furthest_dist:\n",
    "                    break\n",
    "            \n",
    "            node = self.level_graphs[level].get_node(current_id)\n",
    "            if node is None:\n",
    "                continue\n",
    "                \n",
    "            for neighbor_id in node.get_neighbors():\n",
    "                if neighbor_id not in visited:\n",
    "                    visited.add(neighbor_id)\n",
    "                    dist = self.distance(query_id, neighbor_id)\n",
    "                    \n",
    "                    if len(results) < self.ef_construction:\n",
    "                        candidates.put((dist, neighbor_id))\n",
    "                        results.append((neighbor_id, dist))\n",
    "                    else:\n",
    "                        furthest_dist = max(results, key=lambda x: x[1])[1]\n",
    "                        if dist < furthest_dist:\n",
    "                            candidates.put((dist, neighbor_id))\n",
    "                            results.append((neighbor_id, dist))\n",
    "                            results = sorted(results, key=lambda x: x[1])[:self.ef_construction]\n",
    "        \n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "        return results[:self.n_max]\n",
    "    \n",
    "    def beam_search_vector(self, query_vector, entry_point_ids, level, stats=None):\n",
    "        candidates = PriorityQueue()\n",
    "        visited = set()\n",
    "        results = []\n",
    "        \n",
    "        for ep_id in entry_point_ids if isinstance(entry_point_ids, list) else [entry_point_ids]:\n",
    "            dist = self.distance_vector(query_vector, ep_id)\n",
    "            candidates.put((dist, ep_id))\n",
    "            visited.add(ep_id)\n",
    "            results.append((ep_id, dist))\n",
    "            if stats is not None:\n",
    "                stats['distance_computations'] += 1\n",
    "        \n",
    "        while not candidates.empty():\n",
    "            current_dist, current_id = candidates.get()\n",
    "            \n",
    "            if len(results) >= self.ef_construction:\n",
    "                furthest_dist = max(results, key=lambda x: x[1])[1]\n",
    "                if current_dist > furthest_dist:\n",
    "                    break\n",
    "            \n",
    "            node = self.level_graphs[level].get_node(current_id)\n",
    "            if node is None:\n",
    "                continue\n",
    "                \n",
    "            for neighbor_id in node.get_neighbors():\n",
    "                if neighbor_id not in visited:\n",
    "                    visited.add(neighbor_id)\n",
    "                    dist = self.distance_vector(query_vector, neighbor_id)\n",
    "                    if stats is not None:\n",
    "                        stats['distance_computations'] += 1\n",
    "                    \n",
    "                    if len(results) < self.ef_construction:\n",
    "                        candidates.put((dist, neighbor_id))\n",
    "                        results.append((neighbor_id, dist))\n",
    "                    else:\n",
    "                        furthest_dist = max(results, key=lambda x: x[1])[1]\n",
    "                        if dist < furthest_dist:\n",
    "                            candidates.put((dist, neighbor_id))\n",
    "                            results.append((neighbor_id, dist))\n",
    "                            results = sorted(results, key=lambda x: x[1])[:self.ef_construction]\n",
    "        \n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "        return results[:self.n_max]\n",
    "\n",
    "    def add_point(self, point_id, entry_point_id):\n",
    "        for level in range(self.max_levels[point_id] + 1):\n",
    "            self.level_graphs[level].add_node(Node(point_id))\n",
    "        \n",
    "        if point_id == entry_point_id:\n",
    "            return\n",
    "        \n",
    "        if self.max_levels[point_id] > self.max_levels[entry_point_id]:\n",
    "            start_level = self.max_levels[entry_point_id]\n",
    "            beam_entry_point_ids = [entry_point_id]\n",
    "        else:\n",
    "            start_level = self.max_levels[point_id]\n",
    "            closest_id = self.greedy_search(point_id, entry_point_id, stop_at=start_level)\n",
    "            beam_entry_point_ids = [closest_id]\n",
    "        \n",
    "        for level in range(start_level, -1, -1):\n",
    "            neighbors = self.beam_search(point_id, beam_entry_point_ids, level)\n",
    "            \n",
    "            for neighbor_id, dist in neighbors:\n",
    "                if neighbor_id != point_id:\n",
    "                    self.level_graphs[level].add_bi_directional_edge(point_id, neighbor_id)\n",
    "                    \n",
    "                    neighbor_node = self.level_graphs[level].get_node(neighbor_id)\n",
    "                    if len(neighbor_node.get_neighbors()) > self.n_max:\n",
    "                        self.prune_connections(neighbor_id, level)\n",
    "            \n",
    "            beam_entry_point_ids = [n[0] for n in neighbors]\n",
    "    \n",
    "    def prune_connections(self, node_id, level):\n",
    "        node = self.level_graphs[level].get_node(node_id)\n",
    "        neighbors = node.get_neighbors()\n",
    "        \n",
    "        if len(neighbors) <= self.n_max:\n",
    "            return\n",
    "        \n",
    "        neighbor_dists = [(n_id, self.distance(node_id, n_id)) for n_id in neighbors]\n",
    "        neighbor_dists = sorted(neighbor_dists, key=lambda x: x[1])[:self.n_max]\n",
    "        kept_neighbors = set([n_id for n_id, _ in neighbor_dists])\n",
    "        \n",
    "        for neighbor_id in neighbors:\n",
    "            if neighbor_id not in kept_neighbors:\n",
    "                node.remove_neighbor(neighbor_id)\n",
    "                neighbor_node = self.level_graphs[level].get_node(neighbor_id)\n",
    "                if neighbor_node:\n",
    "                    neighbor_node.remove_neighbor(node_id)\n",
    "        \n",
    "    def build_index(self):\n",
    "        self.entry_point_id = 0\n",
    "        self.add_point(0, 0)\n",
    "        \n",
    "        for point_id in range(1, self.sample_nr):\n",
    "            self.add_point(point_id, self.entry_point_id)\n",
    "            \n",
    "            if self.max_levels[point_id] > self.max_levels[self.entry_point_id]:\n",
    "                self.entry_point_id = point_id\n",
    "            \n",
    "            if (point_id + 1) % 100 == 0:\n",
    "                print(f\"Inserted {point_id + 1}/{self.sample_nr} points\")\n",
    "        \n",
    "        print(f\"HNSW index built with {self.sample_nr} points\")\n",
    "        \n",
    "    def search(self, query_id, k=10, ef_search=None):\n",
    "        if ef_search is None:\n",
    "            ef_search = max(self.ef_construction, k)\n",
    "        \n",
    "        if self.entry_point_id is None:\n",
    "            return []\n",
    "        \n",
    "        closest_id = self.greedy_search(query_id, self.entry_point_id, stop_at=0)\n",
    "        \n",
    "        original_ef = self.ef_construction\n",
    "        self.ef_construction = ef_search\n",
    "        results = self.beam_search(query_id, [closest_id], level=0)\n",
    "        self.ef_construction = original_ef\n",
    "        \n",
    "        return results[:k]\n",
    "    \n",
    "    def search_vector(self, query_vector, k=10, ef_search=None, return_stats=False):\n",
    "        if ef_search is None:\n",
    "            ef_search = max(self.ef_construction, k)\n",
    "        \n",
    "        if self.entry_point_id is None:\n",
    "            return []\n",
    "        \n",
    "        stats = {\n",
    "            'levels_visited': [],\n",
    "            'distance_computations': 0,\n",
    "            'entry_point_level': self.max_levels[self.entry_point_id]\n",
    "        }\n",
    "        \n",
    "        closest_id = self.greedy_search_vector(query_vector, self.entry_point_id, stop_at=0, stats=stats)\n",
    "        \n",
    "        original_ef = self.ef_construction\n",
    "        self.ef_construction = ef_search\n",
    "        results = self.beam_search_vector(query_vector, [closest_id], level=0, stats=stats)\n",
    "        self.ef_construction = original_ef\n",
    "        \n",
    "        results = results[:k]\n",
    "        \n",
    "        if return_stats:\n",
    "            return results, stats\n",
    "        return results\n",
    "    \n",
    "    def brute_force_search(self, query_vector, k=10):\n",
    "        distances = [(i, self.distance_vector(query_vector, i)) for i in range(self.sample_nr)]\n",
    "        distances = sorted(distances, key=lambda x: x[1])\n",
    "        return distances[:k]\n",
    "        \n",
    "    def initialize_graph(self):\n",
    "        self.max_levels = self.draw_levels()\n",
    "        self.maximum_height = self.max_levels.max()\n",
    "        self.setup_level_graphs()\n",
    "\n",
    "\n",
    "\n",
    "hnsw = HNSW(number_of_samples, N_max)\n",
    "print(f\"Building HNSW index with {number_of_samples} points...\")\n",
    "hnsw.build_index()\n",
    "\n",
    "# Generate random query vector\n",
    "query_vector = np.random.random(d)\n",
    "k = 10\n",
    "\n",
    "# HNSW search with stats\n",
    "hnsw_results, stats = hnsw.search_vector(query_vector, k=k, return_stats=True)\n",
    "\n",
    "print(f\"Distance computations: {stats['distance_computations']}\")\n",
    "print(f\"Entry point level: {stats['entry_point_level']}\")\n",
    "print(f\"\\nTop {k} results:\")\n",
    "for i, (neighbor_id, dist) in enumerate(hnsw_results, 1):\n",
    "    print(f\"  {i}. Point {neighbor_id}: distance = {dist:.4f}\")\n",
    "\n",
    "# Brute force search\n",
    "print(\"BRUTE FORCE SEARCH\")\n",
    "brute_results = hnsw.brute_force_search(query_vector, k=k)\n",
    "\n",
    "print(f\"Distance computations: {number_of_samples}\")\n",
    "print(f\"\\nTop {k} results:\")\n",
    "for i, (neighbor_id, dist) in enumerate(brute_results, 1):\n",
    "    print(f\"  {i}. Point {neighbor_id}: distance = {dist:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(\"COMPARISON\")\n",
    "print(f\"Distance computation reduction: {number_of_samples/stats['distance_computations']:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16fe4a-6a61-43bc-b357-f1c962a604cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
